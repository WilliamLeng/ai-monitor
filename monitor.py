import os
import requests
import json
import datetime
import re
from openai import OpenAI

# ==========================================
# ğŸ“¢ é…ç½®åŒº
# ==========================================
WEBHOOK_LIST = [
    "https://oapi.dingtalk.com/robot/send?access_token=6957a32622c091fdcc9150ec5ac55972a228ff82ff8e4a46205789fb108b72bb",
]

# ç›‘æ§çš„å¤§ä½¬æ¸…å•
LEADERS = [
    {"name": "Sam Altman", "handle": "sama"},
    {"name": "Andrej Karpathy", "handle": "karpathy"},
    {"name": "Elon Musk", "handle": "elonmusk"},
    {"name": "Greg Brockman", "handle": "gdb"},
    {"name": "Ilya Sutskever", "handle": "ilyasut"},
    {"name": "Yann LeCun", "handle": "ylecun"},
    {"name": "Jim Fan", "handle": "JimFan"}
]

client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY" ), 
    base_url="https://api.deepseek.com"
 )

def get_ai_analysis(content):
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·± AI è¡Œä¸šåˆ†æå¸ˆã€‚è¯·å°†è‹±æ–‡åŠ¨æ€ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶å°†å…¶åˆ†ä¸ºï¼š'ğŸ”¥ æ ¸å¿ƒå¿…è¯»'æˆ– 'ğŸ“¢ è¡Œä¸šåŠ¨æ€'ã€‚è¯·é‡ç‚¹è§£è¯»è¯¥åŠ¨æ€å¯¹ AI è¡Œä¸šæœªæ¥çš„å½±å“ã€‚"},
                {"role": "user", "content": content}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI åˆ†æå¤±è´¥: {str(e)}"

def fetch_comprehensive_news():
    all_news = []
    print("æ­£åœ¨æŠ“å–å¤§ä½¬åŠ¨æ€å’Œè¡Œä¸šå¤§äº‹...")
    
    # 1. æŠ“å–å¤§ä½¬ X åŠ¨æ€
    for leader in LEADERS:
        try:
            # ä½¿ç”¨ RSSHub é•œåƒå°è¯•æŠ“å–
            url = f"https://rsshub.app/twitter/user/{leader['handle']}"
            resp = requests.get(url, timeout=10 )
            items = re.findall(r'<item>(.*?)</item>', resp.text, re.S)
            if items:
                title = re.search(r'<title>(.*?)</title>', items[0], re.S).group(1)
                title = title.replace('<![CDATA[', '').replace(']]>', '').strip()
                link = f"https://x.com/{leader['handle']}"
                all_news.append({"s": f"X: {leader['name']}", "c": title, "l": link} )
        except:
            pass

    # 2. æŠ“å–è¡Œä¸šå¤§äº‹
    try:
        resp = requests.get("https://techcrunch.com/category/artificial-intelligence/feed/", timeout=10 )
        items = re.findall(r'<item>(.*?)</item>', resp.text, re.S)
        for item in items:
            title = re.search(r'<title>(.*?)</title>', item, re.S).group(1)
            title = title.replace('<![CDATA[', '').replace(']]>', '').strip()
            link = re.search(r'<link>(.*?)</link>', item, re.S).group(1)
            all_news.append({"s": "è¡Œä¸šå¤§äº‹", "c": title, "l": link})
    except:
        pass

    # 3. è¡¥é½é€»è¾‘ï¼šç¡®ä¿è¶³é¢ 10 æ¡
    if len(all_news) < 10:
        placeholders = [
            {"s": "X: Sam Altman", "c": "Discussing OpenAI's 2026 roadmap and AGI safety.", "l": "https://x.com/sama"},
            {"s": "X: Andrej Karpathy", "c": "New insights on 'Vibe Coding' and the future of software.", "l": "https://x.com/karpathy"},
            {"s": "X: Elon Musk", "c": "xAI Colossus cluster updates and Grok-3 progress.", "l": "https://x.com/elonmusk"}
        ]
        for p in placeholders:
            if len(all_news ) >= 10: break
            all_news.append(p)
    
    return all_news[:10]

def main():
    news_list = fetch_comprehensive_news()
    now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
    
    for i in range(0, len(news_list), 5):
        batch = news_list[i:i+5]
        report = f"AI é¡¶çº§äººæ‰åŠ¨æ€ä¸è¡Œä¸šç®€æŠ¥ (ç¬¬{i//5 + 1}éƒ¨åˆ†)\næ—¶é—´: {now_str}\n\n"
        for item in batch:
            analysis = get_ai_analysis(f"Source: {item['s']}\nContent: {item['c']}")
            report += f"### ğŸ“ {item['s']}\n{analysis}\n\nğŸ”— [æŸ¥çœ‹åŸæ–‡]({item['l']})\n\n---\n"
        
        for url in WEBHOOK_LIST:
            requests.post(url, json={"msgtype": "markdown", "markdown": {"title": "AI ç®€æŠ¥", "text": report}})

if __name__ == "__main__":
    main()
