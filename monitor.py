import os
import requests
import json
import datetime
import re
from openai import OpenAI

# ==========================================
# ğŸ“¢ é…ç½®åŒº
# ==========================================
WEBHOOK_LIST = [
    "https://oapi.dingtalk.com/robot/send?access_token=6957a32622c091fdcc9150ec5ac55972a228ff82ff8e4a46205789fb108b72bb",
]

# å®æ—¶æ–°é—»æº (RSS )
NEWS_SOURCES = [
    "https://techcrunch.com/category/artificial-intelligence/feed/",
    "https://www.theverge.com/ai-artificial-intelligence/rss/index.xml"
]

client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY" ), 
    base_url="https://api.deepseek.com"
 )

def get_ai_analysis(content):
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·± AI è¡Œä¸šåˆ†æå¸ˆã€‚è¯·å°†è‹±æ–‡åŠ¨æ€ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶å°†å…¶åˆ†ä¸ºä¸¤ç±»ï¼š'ğŸ”¥ æ ¸å¿ƒå¿…è¯»'æˆ– 'ğŸ“¢ è¡Œä¸šåŠ¨æ€'ã€‚è¯·ç®€è¦è¯´æ˜ç†ç”±ã€‚"},
                {"role": "user", "content": content}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI åˆ†æå¤±è´¥: {str(e)}"

def fetch_real_time_news():
    all_news = []
    print("æ­£åœ¨æŠ“å–å®æ—¶æ–°é—»...")
    for url in NEWS_SOURCES:
        try:
            # å¢åŠ è¶…æ—¶è®¾ç½®ï¼Œé˜²æ­¢å¡æ­»
            resp = requests.get(url, timeout=15)
            # æ”¹è¿›æ­£åˆ™åŒ¹é…
            items = re.findall(r'<item>(.*?)</item>', resp.text, re.S)
            for item in items[:5]:
                title_match = re.search(r'<title>(.*?)</title>', item, re.S)
                if title_match:
                    title = title_match.group(1)
                    title = title.replace('<![CDATA[', '').replace(']]>', '').strip()
                    all_news.append({"s": "å®æ—¶æ–°é—»", "c": title})
        except Exception as e:
            print(f"æŠ“å– {url} å¤±è´¥: {e}")
    
    # ã€ä¿åº•æœºåˆ¶ã€‘å¦‚æœå®æ—¶æŠ“å–ä¸åˆ°ï¼Œä½¿ç”¨æœ€æ–°çš„è¡Œä¸šçƒ­ç‚¹ä½œä¸ºè¡¥å……
    if not all_news:
        print("å®æ—¶æŠ“å–æœªè·å¾—å†…å®¹ï¼Œä½¿ç”¨ä¿åº•æ•°æ®...")
        all_news = [
            {"s": "è¡Œä¸šçƒ­ç‚¹", "c": "OpenAI and other AI labs are shifting focus to agentic workflows in 2025."},
            {"s": "è¡Œä¸šçƒ­ç‚¹", "c": "Nvidia continues to dominate the AI chip market with new Blackwell architecture."},
            {"s": "è¡Œä¸šçƒ­ç‚¹", "c": "The debate over AI safety and open-source models intensifies globally."}
        ]
    
    return all_news[:10]

def send_to_all_groups(title, text):
    for url in WEBHOOK_LIST:
        if "access_token" not in url: continue
        try:
            resp = requests.post(url, json={"msgtype": "markdown", "markdown": {"title": title, "text": text}})
            print(f"é’‰é’‰è¿”å›: {resp.text}")
        except Exception as e:
            print(f"å‘é€å¤±è´¥: {e}")

def main():
    news_list = fetch_real_time_news()
    now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
    
    print(f"å‡†å¤‡æ¨é€ {len(news_list)} æ¡èµ„è®¯...")
    
    for i in range(0, len(news_list), 5):
        batch = news_list[i:i+5]
        report = f"# ğŸ¤– AI å®æ—¶èµ„è®¯ç®€æŠ¥ (ç¬¬{i//5 + 1}éƒ¨åˆ†)\n> æ—¶é—´: {now_str}\n\n"
        for item in batch:
            analysis = get_ai_analysis(f"Source: {item['s']}\nContent: {item['c']}")
            report += f"### ğŸ“ {item['s']}\n{analysis}\n\n---\n"
        
        send_to_all_groups(f"AI å®æ—¶ç®€æŠ¥ Part {i//5 + 1}", report)

if __name__ == "__main__":
    main()
